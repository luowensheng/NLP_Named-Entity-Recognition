{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import sys\n",
    "import nltk\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import json\n",
    "from copy import deepcopy as cp\n",
    "import numpy as np\n",
    "from numpy import linalg as mt\n",
    "from pinyin import get as ctp\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from unidecode import unidecode as und\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Word2Vec data to build a Chinese NER system\n",
    "\n",
    " We use Chinese data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training and validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdata(path):    \n",
    "    with open(path, 'r',encoding=\"utf-8\") as f:\n",
    "     \tout= json.load(f)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train=readdata('train_char.json')\n",
    "validation=readdata('validation_char.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first sentence in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['記', 'VK', 'O'],\n",
       " ['得', 'VK', 'O'],\n",
       " ['小', 'Nd', 'B_Time'],\n",
       " ['時', 'Nd', 'I_Time'],\n",
       " ['候', 'Nd', 'I_Time'],\n",
       " ['，', 'COMMACATEGORY', 'O'],\n",
       " ['媽', 'Na', 'B_Person'],\n",
       " ['媽', 'Na', 'I_Person'],\n",
       " ['說', 'VE', 'O'],\n",
       " ['起', 'VE', 'O'],\n",
       " ['哪', 'Nep', 'O'],\n",
       " ['個', 'Nf', 'O'],\n",
       " ['典', 'VH', 'O'],\n",
       " ['型', 'VH', 'O'],\n",
       " ['敗', 'Na', 'B_Person'],\n",
       " ['家', 'Na', 'I_Person'],\n",
       " ['子', 'Na', 'I_Person'],\n",
       " ['形', 'Na', 'O'],\n",
       " ['象', 'Na', 'O'],\n",
       " ['，', 'COMMACATEGORY', 'O'],\n",
       " ['掛', 'VC', 'O'],\n",
       " ['在', 'P', 'O'],\n",
       " ['嘴', 'Na', 'O'],\n",
       " ['邊', 'Ncd', 'O'],\n",
       " ['的', 'DE', 'O'],\n",
       " ['就', 'Cbb', 'O'],\n",
       " ['是', 'Cbb', 'O'],\n",
       " ['那', 'Nep', 'B_Person'],\n",
       " ['人', 'Na', 'I_Person'],\n",
       " ['吃', 'VC', 'O'],\n",
       " ['喝', 'VC', 'O'],\n",
       " ['嫖', 'Na', 'O'],\n",
       " ['賭', 'Na', 'O'],\n",
       " ['癮', 'Na', 'O'],\n",
       " ['五', 'Na', 'O'],\n",
       " ['毒', 'Na', 'O'],\n",
       " ['俱', 'VH', 'O'],\n",
       " ['全', 'VH', 'O'],\n",
       " ['。', 'PERIODCATEGORY', 'O']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Data=cp(train)\n",
    "for x in validation:\n",
    "    Data.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word2vec1 = KeyedVectors.load_word2vec_format(\"ch.300.bin\", binary=True)\n",
    "word2vec2= KeyedVectors.load_word2vec_format(\"cna.word2vec.bin\", binary=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(word2vec):\n",
    "    Dict=dict()\n",
    "    for x in word2vec.vocab:\n",
    "        if x not in Dict:\n",
    "           Dict[x]=word2vec.wv[x]\n",
    "    return Dict \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Dict_wv_1=get_dict(word2vec1)\n",
    "Dict_wv_2=get_dict(word2vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ac_dict(train_word,Dict):\n",
    "    cDict=dict()\n",
    "    for x in train_word:\n",
    "      for j in x:\n",
    "        if j[0] in Dict:\n",
    "         if j[0] not in cDict:\n",
    "            cDict[j[0]]= Dict[j[0]]\n",
    "        else:\n",
    "             cDict[j[0]]=np.zeros(len(Dict['是']))\n",
    "    return  cDict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 261 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DDict=Ac_dict(Data,Dict_wv_1)\n",
    "DDict2=Ac_dict(Data,Dict_wv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3976251 ,  0.35810676,  0.13722947,  0.07472387, -0.5475522 ,\n",
       "        0.41480562, -0.11194973,  0.05129677, -0.5257993 ,  0.20008406],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DDict['是'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features 1\n",
    "Refer to sample code method: part-of-speech, upper / lower / titlecase, suﬃx, word length..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):  \n",
    "    word = sent[i][0]  \n",
    "    postag = sent[i][1]  \n",
    "    \n",
    "    features = {  \n",
    "\n",
    "        'bias': 1.0,  \n",
    "\n",
    "        'word.lower()': word,  \n",
    "        'word.istitle()': word.istitle(),  \n",
    "        'word.isdigit()': word.isdigit(),  \n",
    "        'word.isnumeric()': word.isnumeric(),   \n",
    "        \n",
    "        'postag': postag,  \n",
    "        'word.istitle()': postag.istitle(), \n",
    "        'postag[:2]': postag[:2],   \n",
    "    }  \n",
    " \n",
    "    if i > 0:  \n",
    "  \n",
    "        word1 = sent[i-1][0]  \n",
    "        postag1 = sent[i-1][1]    \n",
    "        features.update({  \n",
    "            \n",
    "            '-1:word.lower()': word1, \n",
    "            '-1:postag': postag1,  \n",
    "            '-1:word.istitle()': postag1.istitle(),  \n",
    "            '-1:postag[:2]': postag1[:2],                \n",
    "        })  \n",
    "\n",
    "    else:   \n",
    "\n",
    "        features['BOS'] = True  \n",
    "\n",
    "    if i < len(sent)-1:  \n",
    "\n",
    "        word1 = sent[i+1][0]  \n",
    "        postag1 = sent[i+1][1]  \n",
    "        features.update({  \n",
    "\n",
    "            '+1:word.lower()': word1,  \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isdigit()': word1.isdigit(), \n",
    "            '+1:word.isnumeric()': word1.isnumeric(), \n",
    "            \n",
    "            '+1:postag': postag1,   \n",
    "            '+1:word.istitle()': postag1.istitle(), \n",
    "            '+1:postag[:2]': postag1[:2],  \n",
    "        })  \n",
    " \n",
    "\n",
    "    else:  \n",
    "\n",
    "        features['EOS'] = True  \n",
    "\n",
    "    return features  \n",
    "\n",
    "def sent2features(sent):    \n",
    "    return [word2features(sent, i) for i in range(len(sent))]  \n",
    "\n",
    "def sent2labels(sent):  \n",
    "    return [label for token, postag, label in sent]  \n",
    "\n",
    "def sent2tokens(sent):  \n",
    "    return [token for token, postag, label in sent] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what word2features extracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': '記',\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'word.isnumeric()': False,\n",
       " 'postag': 'VK',\n",
       " 'postag[:2]': 'VK',\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': '得',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isdigit()': False,\n",
       " '+1:word.isnumeric()': False,\n",
       " '+1:postag': 'VK',\n",
       " '+1:postag[:2]': 'VK'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train ]\n",
    "y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "X_test = [sent2features(s) for s in validation]\n",
    "y_test = [sent2labels(s) for s in validation]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word2vec.vocab['清明'].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To see all possible CRF parameters check its docstring. Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "There is much more O entities in data set, but we're more interested in other entities. To account for this we'll use averaged F1 score computed for all labels except for O. ``sklearn-crfsuite.metrics`` package provides some useful metrics for sequence classification task, including this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B_Time',\n",
       " 'I_Time',\n",
       " 'B_Person',\n",
       " 'I_Person',\n",
       " 'B_Thing',\n",
       " 'I_Thing',\n",
       " 'B_Location',\n",
       " 'B_Metric',\n",
       " 'I_Metric',\n",
       " 'I_Location',\n",
       " 'B_Organization',\n",
       " 'I_Organization',\n",
       " 'B_Abstract',\n",
       " 'I_Abstract',\n",
       " 'B_Physical',\n",
       " 'I_Physical',\n",
       " 'B_Term',\n",
       " 'I_Term',\n",
       " 'B_ABstract',\n",
       " 'I_ABstract']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.29 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.700603315943222"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect per-class results in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    B_ABstract      0.000     0.000     0.000         0\n",
      "    I_ABstract      0.000     0.000     0.000         0\n",
      "    B_Abstract      0.671     0.378     0.483       135\n",
      "    I_Abstract      0.647     0.437     0.521       591\n",
      "    B_Location      0.709     0.617     0.660      1826\n",
      "    I_Location      0.697     0.657     0.676      3237\n",
      "      B_Metric      0.563     0.467     0.511       304\n",
      "      I_Metric      0.673     0.644     0.658       626\n",
      "B_Organization      0.528     0.272     0.359       243\n",
      "I_Organization      0.588     0.352     0.441       647\n",
      "      B_Person      0.863     0.857     0.860      4013\n",
      "      I_Person      0.786     0.793     0.790      3181\n",
      "    B_Physical      0.000     0.000     0.000         1\n",
      "    I_Physical      0.000     0.000     0.000         7\n",
      "        B_Term      0.000     0.000     0.000         0\n",
      "        I_Term      0.000     0.000     0.000         0\n",
      "       B_Thing      0.659     0.683     0.671      3142\n",
      "       I_Thing      0.614     0.692     0.650      3421\n",
      "        B_Time      0.749     0.597     0.664       905\n",
      "        I_Time      0.775     0.641     0.702      2163\n",
      "\n",
      "     micro avg      0.721     0.688     0.704     24442\n",
      "     macro avg      0.476     0.404     0.432     24442\n",
      "  weighted avg      0.721     0.688     0.701     24442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New method using a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):  \n",
    "    word = sent[i][0]  \n",
    "    postag = sent[i][1]  \n",
    "\n",
    "    punc=[x[1] for x in sent if len(x[1])>6]  \n",
    " \n",
    "    features = {  \n",
    "\n",
    "        'bias': 1.0,  \n",
    "\n",
    "        'word.lower()': word,  \n",
    "        'word.words':words[word],\n",
    "        'word.istitle()': word.istitle(),  \n",
    "        'word.isdigit()': word.isdigit(),  \n",
    "        'word.isnumeric()': word.isnumeric(),   \n",
    "        \n",
    "        'postag': postag,  \n",
    "        'word.istitle()': postag.istitle(), \n",
    "        'postag[:2]': postag[:2],   \n",
    "    }  \n",
    " \n",
    "    if i > 0:  \n",
    "        \n",
    "        word1 = sent[i-1][0]  \n",
    "        postag1 = sent[i-1][1]    \n",
    "        features.update({  \n",
    "            \n",
    "            '-1:word.lower()': word1, \n",
    "            '-1:postag': postag1, \n",
    "            '-1:word.istitle()': postag1.istitle(),  \n",
    "            '-1:postag[:2]': postag1[:2],  \n",
    "            'post.com':tags[postag1]>tags[postag],          \n",
    "        })  \n",
    "\n",
    "    else:   \n",
    "\n",
    "        features['BOS'] = True  \n",
    "\n",
    "    if i < len(sent)-1:  \n",
    "\n",
    "        word1 = sent[i+1][0]  \n",
    "\n",
    "        postag1 = sent[i+1][1]  \n",
    "\n",
    "        features.update({  \n",
    "\n",
    "            '+1:word.lower()': word1,\n",
    "            'compare': words[word1]<words[word],\n",
    "                \n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isdigit()': word1.isdigit(), \n",
    "            '+1:word.isnumeric()': word1.isnumeric(), \n",
    "           \n",
    "            '+1:postag': postag1,   \n",
    "            '+1:postag.tags': tags[postag1],\n",
    "            '+1:word.istitle()': postag1.istitle(), \n",
    "            '+1:postag[:2]': postag1[:2],  \n",
    "            'post.com2':tags[postag]>tags[postag1],\n",
    "\n",
    "        })  \n",
    "\n",
    "    else:  \n",
    "\n",
    "        features['EOS'] = True  \n",
    "\n",
    "    return features   \n",
    "\n",
    "def sent2features(sent):    \n",
    "    return [word2features(sent, i) for i in range(len(sent))]  \n",
    "\n",
    "def sent2labels(sent):  \n",
    "    return [label for token, postag, label in sent]  \n",
    "\n",
    "def sent2tokens(sent):  \n",
    "    return [token for token, postag, label in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=dict()     \n",
    "for x in Data:\n",
    "    for j in x:\n",
    "        if j[0] not in words:\n",
    "            words[j[0]]=1/50000\n",
    "        else:\n",
    "            words[j[0]]+=1/50000\n",
    "\n",
    "\n",
    "tags=dict()     \n",
    "for x in Data:\n",
    "    for j in x:\n",
    "        if j[1] not in tags:\n",
    "            tags[j[1]]=1/300000\n",
    "        else:\n",
    "            tags[j[1]]+=1/300000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': '記',\n",
       " 'word.words': 0.01829999999999959,\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'word.isnumeric()': False,\n",
       " 'postag': 'VK',\n",
       " 'postag[:2]': 'VK',\n",
       " 'BOS': True,\n",
       " '+1:word.lower()': '得',\n",
       " 'compare': False,\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isdigit()': False,\n",
       " '+1:word.isnumeric()': False,\n",
       " '+1:postag': 'VK',\n",
       " '+1:postag.tags': 0.037703333333338675,\n",
       " '+1:postag[:2]': 'VK',\n",
       " 'post.com2': False}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train]\n",
    "y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "X_test = [sent2features(s) for s in validation]\n",
    "y_test = [sent2labels(s) for s in validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7009598051992496"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    B_ABstract      0.000     0.000     0.000         0\n",
      "    I_ABstract      0.000     0.000     0.000         0\n",
      "    B_Abstract      0.686     0.356     0.468       135\n",
      "    I_Abstract      0.671     0.408     0.507       591\n",
      "    B_Location      0.710     0.617     0.660      1826\n",
      "    I_Location      0.701     0.658     0.679      3237\n",
      "      B_Metric      0.570     0.470     0.515       304\n",
      "      I_Metric      0.668     0.644     0.656       626\n",
      "B_Organization      0.515     0.280     0.363       243\n",
      "I_Organization      0.574     0.354     0.438       647\n",
      "      B_Person      0.862     0.858     0.860      4013\n",
      "      I_Person      0.782     0.795     0.789      3181\n",
      "    B_Physical      0.000     0.000     0.000         1\n",
      "    I_Physical      0.000     0.000     0.000         7\n",
      "        B_Term      0.000     0.000     0.000         0\n",
      "        I_Term      0.000     0.000     0.000         0\n",
      "       B_Thing      0.661     0.686     0.673      3142\n",
      "       I_Thing      0.619     0.695     0.655      3421\n",
      "        B_Time      0.747     0.594     0.662       905\n",
      "        I_Time      0.769     0.642     0.700      2163\n",
      "\n",
      "     micro avg      0.722     0.688     0.705     24442\n",
      "     macro avg      0.477     0.403     0.431     24442\n",
      "  weighted avg      0.721     0.688     0.701     24442\n",
      "\n",
      "Wall time: 2.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method 3 ( word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(word2vec for second self_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real(Dict):\n",
    "   Real=dict()\n",
    "   for x in Dict:\n",
    "    if x not in Real:\n",
    "        Real[x]=dict()\n",
    "        for j in range(len(Dict[x])):\n",
    "            Real[x]['num'+str(j+1)]=Dict[x][j]\n",
    "   return Real  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 759 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "Real=get_real(DDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):  \n",
    "    features=Real[sent[i][0] ]\n",
    "    return features  \n",
    "\n",
    "def sent2features(sent):  \n",
    "    return [word2features(sent, i) for i in range(len(sent))]    \n",
    "\n",
    "def sent2labels(sent):  \n",
    "    return [label for token, postag, label in sent]  \n",
    "\n",
    "def sent2tokens(sent):  \n",
    "    return [token for token, postag, label in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sent2features(train[0])[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%time is a cell magic, but the cell body is empty. Did you mean the line magic %time (single %)?\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train]\n",
    "y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "X_test = [sent2features(s) for s in validation]\n",
    "y_test = [sent2labels(s) for s in validation]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    B_ABstract      0.000     0.000     0.000         0\n",
      "    I_ABstract      0.000     0.000     0.000         0\n",
      "    B_Abstract      0.810     0.504     0.621       135\n",
      "    I_Abstract      0.627     0.607     0.617       591\n",
      "    B_Location      0.469     0.143     0.219      1826\n",
      "    I_Location      0.441     0.194     0.270      3237\n",
      "      B_Metric      0.354     0.112     0.170       304\n",
      "      I_Metric      0.357     0.131     0.192       626\n",
      "B_Organization      0.256     0.041     0.071       243\n",
      "I_Organization      0.267     0.164     0.203       647\n",
      "      B_Person      0.833     0.567     0.675      4013\n",
      "      I_Person      0.384     0.268     0.316      3181\n",
      "    B_Physical      0.000     0.000     0.000         1\n",
      "    I_Physical      0.000     0.000     0.000         7\n",
      "        B_Term      0.000     0.000     0.000         0\n",
      "        I_Term      0.000     0.000     0.000         0\n",
      "       B_Thing      0.327     0.101     0.154      3142\n",
      "       I_Thing      0.252     0.099     0.143      3421\n",
      "        B_Time      0.553     0.231     0.326       905\n",
      "        I_Time      0.607     0.367     0.458      2163\n",
      "\n",
      "     micro avg      0.507     0.259     0.343     24442\n",
      "     macro avg      0.327     0.176     0.222     24442\n",
      "  weighted avg      0.475     0.259     0.328     24442\n",
      "\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)\n",
    "\n",
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results for the second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(word2vec for second pre_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "Real=get_real(DDict2)\n",
    "\n",
    "%%time\n",
    "X_train = [sent2features(s) for s in train]\n",
    "y_train = [sent2labels(s) for s in train]\n",
    "\n",
    "X_test = [sent2features(s) for s in validation]\n",
    "y_test = [sent2labels(s) for s in validation]\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)\n",
    "\n",
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word-Based "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_word=readdata('validation_word.json')\n",
    "train_word=readdata('train_word.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Here i create a dictionary to find most common words for each label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def find_after(train_word,label):\n",
    "  B=dict()\n",
    "  for x in train_word:\n",
    "    for j in range(len(x)-1):\n",
    "        if x[j][label] not in B:\n",
    "           B[x[j][label]]=dict()\n",
    "        f=[x for x in x[j+1][0]]\n",
    "        for c in f:\n",
    "            if c not in B[x[j][label]]:\n",
    "               B[x[j][label]][c]=1\n",
    "            else:\n",
    "               B[x[j][label]][c]+=1 \n",
    "        \n",
    "  s=cp(B)\n",
    "  for x in B:\n",
    "    for j in B[x]:\n",
    "        B[x][j]/=sum(s[x].values())\n",
    "\n",
    "\n",
    "  s=cp(B)\n",
    "  for x in B:\n",
    "    for j in B[x]:\n",
    "        B[x][j]/=max(s[x].values())\n",
    "\n",
    "\n",
    "  N2=dict()\n",
    "\n",
    "  for x in B:\n",
    "    N2[x]=[y for y in B[x] if B[x][y]>0.4]\n",
    "\n",
    "  return N2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intersection(lst1, lst2): \n",
    "    lst3 = [value for value in lst1 if value in lst2] \n",
    "    return lst3 \n",
    "\n",
    "def word2features(sent, i):  \n",
    "\n",
    "    word = sent[i][0]  \n",
    "    postag = sent[i][1]  \n",
    "    c=0.0001\n",
    "    features = {  \n",
    "\n",
    "        'bias': 1.0,  \n",
    "        'word.lower()': word,  \n",
    "        'word.last':word[-1],\n",
    "        'word[0]': word[0],  \n",
    "        'word.b':i==0,\n",
    "        'word.l':i==len(sent)-1,\n",
    "        'word.p':np.round(10*(i-len(sent)-1)/(len(sent)-1+c))/10,\n",
    "        'postag.l': len(postag)>6, \n",
    "        'postag[:2]': postag[:2],             \n",
    "    }  \n",
    "    if i > 1:  \n",
    "\n",
    "        word1 = sent[i-1][0]  \n",
    "        postag1 = sent[i-1][1]  \n",
    "\n",
    "        features.update({  \n",
    "                \n",
    "            '-1:word.lower()': word1,  \n",
    "            '-1:word.last':word1[-1],\n",
    "            '-1:word[0]': word1[0],               \n",
    "            '-1:word.b':i-1==0,\n",
    "            '-1:word.l':i-1==len(sent)-1,\n",
    "            '-1.word.p':np.round(10*(i-1-len(sent)-1)/(len(sent)-1+c))/10,\n",
    "            \n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag.l': len(postag1)>6,\n",
    "            '-1:postag[:2]': postag1[:2],               \n",
    "        })  \n",
    "\n",
    "    else:  \n",
    "\n",
    "        features['BOS'] = True  \n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        \n",
    "        word1 = sent[i+1][0]  \n",
    "        postag1 = sent[i+1][1]  \n",
    "        pre_post=[postag, postag1]\n",
    "\n",
    "        features.update({  \n",
    "            '+1:word.lower()': word1,  \n",
    "            '+1:word.last':word1[-1],\n",
    "            '+1:word[0]': word1[0],  \n",
    "            '+1:postag': postag1, \n",
    "            '+1:postag.l': len(postag1)>6, \n",
    "            '+1:postag[:2]': postag1[:2],  \n",
    "\n",
    "        'B_ABstract.pre_word.a': len(intersection(word1,N2['B_ABstract']))>0,\n",
    "        'B_Abstract.pre_word.a':len(intersection(word1,N2['B_Abstract']))>0,\n",
    "        'B_location.pre_word.a':len(intersection(word1,N2['B_Location']))>0,\n",
    "        'B_Metric.pre_word.a':len(intersection(word1,N2['B_Metric']))>0,\n",
    "        'B_Organization.pre_word.a':len(intersection(word1,N2['B_Organization']))>0,\n",
    "        'B_Person.pre_word.a':len(intersection(word1,N2['B_Person']))>0,\n",
    "        'B_Physical.pre_word.a':len(intersection(word1,N2['B_Physical']))>0,\n",
    "        'B_Term.pre_word.a':len(intersection(word1,N2['B_Term']))>0,\n",
    "        'B_Thing.pre_word.a': len(intersection(word1,N2['B_Thing']))>0,\n",
    "        'B_Time.pre_word.a': len(intersection(word1,N2['B_Time']))>0,\n",
    "        'I_Abstract.pre_word.a': len(intersection(word1,N2['I_Abstract']))>0,\n",
    "        'I_location.pre_word.a': len(intersection(word1,N2['I_Location']))>0,\n",
    "        'I_Metric.pre_word.a': len(intersection(word1,N2['I_Metric']))>0,\n",
    "        'I_Organization.pre_word.a': len(intersection(word1,N2['I_Organization']))>0,\n",
    "        'I_Person.pre_word.a': len(intersection(word1,N2['I_Person']))>0,\n",
    "        'I_Physical.pre_word.a': len(intersection(word1,N2['I_Physical']))>0,\n",
    "        'I_Term.pre_word.a': len(intersection(word1,N2['I_Term']))>0,\n",
    "        'I_Thing.pre_word.a': len(intersection(word1,N2['I_Thing']))>0,\n",
    "        'I_Time.pre_word.a':len(intersection(word1,N2['I_Time']))>0,\n",
    "        'O.pre_word.a':len(intersection(word1,N2['O']))>0, \n",
    "        })    \n",
    "    else:  \n",
    "        features['EOS'] = True  \n",
    "    return features  \n",
    "\n",
    "def sent2features(sent):  \n",
    "    return [word2features(sent, i) for i in range(len(sent))]  \n",
    "\n",
    "def sent2labels(sent):  \n",
    "    return [label for token, postag, label in sent]  \n",
    "\n",
    "def sent2tokens(sent):  \n",
    "    return [token for token, postag, label in sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "N2=find_after(train_word,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_word]\n",
    "y_train = [sent2labels(s) for s in train_word]\n",
    "\n",
    "X_test = [sent2features(s) for s in validation_word]\n",
    "y_test = [sent2labels(s) for s in validation_word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7139510606113944"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "crf= sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "\n",
    "\n",
    "crf.fit(X_train, y_train)\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\oliver\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "    B_ABstract      0.000     0.000     0.000         0\n",
      "    B_Abstract      0.707     0.430     0.535       135\n",
      "    I_Abstract      0.737     0.512     0.604       322\n",
      "    B_Location      0.700     0.626     0.661      1826\n",
      "    I_Location      0.654     0.588     0.619      1233\n",
      "      B_Metric      0.565     0.487     0.523       304\n",
      "      I_Metric      0.591     0.519     0.552       351\n",
      "B_Organization      0.500     0.300     0.375       243\n",
      "I_Organization      0.596     0.363     0.451       248\n",
      "      B_Person      0.895     0.902     0.898      4013\n",
      "      I_Person      0.682     0.639     0.660       728\n",
      "    B_Physical      0.000     0.000     0.000         1\n",
      "    I_Physical      0.000     0.000     0.000         5\n",
      "        B_Term      0.000     0.000     0.000         0\n",
      "        I_Term      0.000     0.000     0.000         0\n",
      "       B_Thing      0.707     0.758     0.731      3144\n",
      "       I_Thing      0.466     0.526     0.494       683\n",
      "        B_Time      0.756     0.643     0.695       905\n",
      "        I_Time      0.724     0.612     0.663       950\n",
      "\n",
      "     micro avg      0.737     0.701     0.718     15091\n",
      "     macro avg      0.488     0.416     0.445     15091\n",
      "  weighted avg      0.733     0.701     0.714     15091\n",
      "\n",
      "Wall time: 736 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sorted_labels= sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    " y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
